\chapter{Algorithms}

How can you classify algorithms? By problem, time complexity, paradigm? 

\begin{description}
    \item[Brute-force] description
    \item[Greedy] description
    \item[Divide and Conquer] description
    \item[Dynamic Programming] description
\end{description}

\section{Searching}

While data structures are \textit{used} for storing data, they are only \textit{useful} if their data can be quickly retrieved. Given a collection of data, how would you find a particular item in it? That is, given a key (something that identifies the item), how would you find the value (the actual item)? Search algorithms are also used to determine if a data structure \textit{contains} a certain value. In this case, instead of returning the value you searched for, you would simply return whether or not the value was found. \\

There are many different kinds of search algorithms and one may be preferable to another depending on the data structure, how the data is ordered, and the key you are given. For data structures like hash maps, searching takes constant time. That is, given a key, you can perform a constant time operation (i.e. hashing) to find the value. Data structures with non-constant search times are more interesting and will be the subjects of this section. Trees and graphs in particular have many possible search algorithms that are useful in different scenarios.

\subsection{Depth-first Search}

Depth-first search (DFS) is a method of traversing trees and graphs. While it is often implemented for the purpose of searching, it is more generally a method of visiting all of the nodes in a tree or graph. It involves starting at a root node and exploring each path as far as possible before searching another path. At each node, you can perform some kind of action (such as comparing the node's data to your key) or move on to another node. \\

For binary trees, each node has two paths. At any node, you can recursively traverse its left path (L), recursively traverse its right path (R), or process the node itself (N). The order in which these actions are performed determine the order in which the tree is searched. Below are some different tree traversals (\textit{pre-order}, \textit{in-order}, \textit{out-order}, \textit{post-order}) that implement these actions in different orders. \\\\

\begin{algorithm}[H]
    \SetKwFunction{Preorder}{void preorder}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\Preorder{$N$}}{
        \Begin{
            \If{$N$ \textup{!=} \textsc{null}}{
                visit($N$); \\
                preorder($N$.\texttt{left}); \\
                preorder($N$.\texttt{right}); \\
            }
        }
    }
    \caption{Pre-order traversal (NLR)}
\end{algorithm}
    \vspace{5mm}
     
\begin{algorithm}[H]
    \SetKwFunction{Inorder}{void inorder}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\Inorder{$N$}}{
        \Begin{
            \If{$N$ \textup{!=} \textsc{null}}{
                inorder($N$.\texttt{left}); \\
                visit($N$); \\
                inorder($N$.\texttt{right}); \\
            }
        }
    }
    \caption{In-order traversal (LNR)}
\end{algorithm}
\vspace{5mm}

\begin{algorithm}[H]
    \SetKwFunction{Outorder}{void outorder}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\Outorder{$N$}}{
        \Begin{
            \If{$N$ \textup{!=} \textsc{null}}{
                outorder($N$.\texttt{right}); \\
                visit($N$); \\
                outorder($N$.\texttt{left}); \\
            }
        }
    }
    \caption{Out-order traversal (RNL)}
\end{algorithm}
\vspace{5mm}

\begin{algorithm}[H]
    \SetKwFunction{Postorder}{void postorder}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\Postorder{$N$}}{
        \Begin{
            \If{$N$ \textup{!=} \textsc{null}}{
                postorder($N$.\texttt{left}); \\
                postorder($N$.\texttt{right}); \\
                visit($N$); \\
            }
        }
    }
    \caption{Post-order traversal (LRN)}
\end{algorithm}
\vspace{5mm}

In a pre-order traversal, every node is visited before its children. This is an example of a \textit{topological sort} or \textit{topological ordering}. In an in-order traversal, nodes are visited left to right. For a binary search tree, an in-order traversal would process nodes in sorted order. Out-order is the opposite of in-order. Nodes are visited right to left, and a binary search tree would be processed in reverse sorted order. In a post-order traversal, every node is visited after its children. It is often used to delete an entire tree, node by node. \\

DFS can also be applied to graphs. Instead of having a left and right path, a node in a graph may have many paths, each of which needs to be explored completely before moving on to the next. However, depth-first searching a graph with a cycle will result in looping through the nodes in that cycle indefinitely. This can be dealt with by ignoring previously visited nodes and/or by stopping the search at a certain depth. \textit{Iterative deepening} is a process that involves depth-first searching to a certain depth and repeating the search with a deeper depth until a given node is found. Recursive and iterative DFS algorithms are given below. They handle cycles by keeping track of visited nodes. \\

\begin{algorithm}[H]
    \SetKwFunction{DFSRecursive}{void dfs-recursive}
    \KwData{A graph $G$ and a node $u$ in $G$}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\DFSRecursive{$G$,$u$}}{
        \Begin{
            Visit $u$; \\
            \ForEach{node $v$ in $G$.adjacentNodes($u$)}{
                \If{$v$ is not visited}{
                    dfs-recursive($G$,$v$);
                }
            }
        }
    }
    \caption{DFS (recursive)}
\end{algorithm}
\vspace{5mm}

\begin{algorithm}[H]
    \SetKwFunction{DFSIterative}{void dfs-iterative}
    \KwData{A graph $G$ and a node $u$ in $G$}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\DFSIterative{$G$,$u$}}{
        \Begin{
            Let $S$ be a stack; \\
            $S\texttt{.push}(u)$; \\
            \While{$S$ is not empty}{
                $u \longleftarrow S\texttt{.pop()}$; \\
                \If{$u$ is not visited}{
                    Visit $u$; \\
                    \ForEach{node $v$ in $G$.adjacentNodes($u$)}{
                        $S\texttt{.push(v)}$;
                    }
                }
            }
        }
    }
    \caption{DFS (iterative)}
\end{algorithm}
\vspace{5mm}

It is important to note that the recursive and iterative implementations of DFS do not search in the same order. For example, if a binary tree is traversed using recursive DFS, nodes at the same depth will be visited left to right. If it is traversed using iterative DFS, nodes at the same depth will be visited right to left because storing them with a stack will invert their order. It seems then that it might be \textit{preferable} to implement DFS recursively.

\begin{table}[H]
    \caption{DFS Computational Complexities}
    \label{tab:dfs}
    \begin{tabularx}{\textwidth}{|c|c|X|}
        \vtabularspace{3}
        \hline
        Resource & Complexity & \multicolumn{1}{c|}{Reasoning} \\
        \hline
        Time & $O(|V|+|E|)$ & The search must visit every node and walk every path. \\
        Space & $O(|V|)$ & The call stack would hold $|V|$ frames if the tree was a path. The stack would have to hold $|V|-1$ nodes if the root were connected to every other node. \\
        \hline
        \vtabularspace{3}
    \end{tabularx}
\end{table}

\subsection{Breadth-first Search}

Breadth-first search (BFS) is another way of traversing trees and graphs. Like DFS, it is often used as a method of searching trees, but in general it is just a method to visit every node in a tree or graph. Unlike DFS, it visits all neighbors of a node before visiting deeper nodes. \\

Unlike DFS, BFS does not have a variety of orders like pre-order, in-order, etc. when applied to a tree. Typically, nodes in the same level will be visited left to right and shallow levels will be processed before deep levels, but the latter rule is the only true requirement of a BFS. Like DFS, BFS can be written recursively, but it is much more natural to write it iteratively, so that algorithm will be given first. \\

\begin{algorithm}[H]
    \SetKwFunction{BFSIterative}{void bfs-iterative}
    \KwData{A graph $G$ and a node $u$ in $G$}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\BFSIterative{$G$,$u$}}{
        \Begin{
            Let $Q$ be a queue; \\
            $Q$\texttt{.enqueue($u$)}; \\
            \While{$Q$ is not empty}{
                $u \longleftarrow Q\texttt{.dequeue()}$; \\
                \If{$u$ is not visited}{
                    Visit $u$; \\
                    \ForEach{node $v$ in G.adjacentNodes($u$)}{
                        $Q$\texttt{.enqueue($v$)};
                    }
                }
            }
        }
    }
    \caption{BFS (iterative)}
\end{algorithm}
\vspace{5mm}

Note that the only difference between the iterative implementations of DFS and BFS is the choice of data structure. DFS uses a stack to hold the next nodes to visit while BFS uses a queue. This explains why DFS is natural to write recursively, and BFS is not. In \texttt{dfs-iterative}, a stack is used to store the next nodes to visit. In \texttt{dfs-recursive}, the algorithm stores its recursive subroutines on the \textit{call stack} which is a stack data structure. Instead of storing the next nodes to visit, \texttt{dfs-recursive} stores a subroutine that will find and visit the next nodes. \\

BFS can be written using recursion, but it will essentially require implementing a stack (the call stack) into the algorithm. This is not a very \textit{meaningful} way to implement BFS. In fact, it is more like implementing DFS and running it on a single-branch tree in which each node contains the BFS queue's state at some particular step during a regular, iterative BFS. Despite its inherent awkwardness, a recursive implementation of BFS is shown below. \\

\begin{algorithm}[H]
    \SetKwFunction{BFSRecursive}{void bfs-recursive}
    \SetKwFunction{BFSRecursiveHelper}{void bfs-recursive-helper}
    \SetKwProg{Fn}{}{:}{}
    \KwData{A graph $G$ and a node $u$ in $G$}
    \Fn{\BFSRecursive{$G$,$u$}}{
        \Begin{
            Let $Q$ be a queue; \\
            $Q$\texttt{.enqueue($u$)}; \\
            \texttt{bfs-recursive-helper($G$,$Q$)};
        }
    }
    \vspace{2mm}
    \KwData{$Q$}
    \Fn{\BFSRecursiveHelper{$G$,$Q$}}{
        \Begin{
            \If{Q is not empty}{
                $u \longleftarrow Q$\texttt{.dequeue()}; \\
                Visit $u$; \\
                \ForEach{node $v$ in G.adjacentNodes($u$)}{
                    $Q$\texttt{.enqueue($v$)};
                }
                \texttt{bfs-recursive-helper($G$,$Q$)};
            } 
        }
    }
    \caption{BFS (recursive)}
\end{algorithm}
\vspace{5mm}

The space complexity of this implementation is particularly bad. If you needed to visit $|V|$ nodes, you would have to store $|V|$ queues at once. In a binary tree, when a full node is visited, one node is dequeued and two are enqueued, which increments the size of the queue by 1. When the node has one child, the queue does not change size. When the node has no children, the queue's size decrements by 1. In the worst-case (which occurs if the tree is perfect), the queue would increment in size by 1 until the last level. As BFS visits the nodes in the last level, the queue would decrement by 1, starting at a size of $log\;|V|$ and ending empty when the final node is explored. At this point, the call stack would start unwinding. The average queue size in this case would be $\rfrac{1}{2}\cdot log\;|V|$, so the space complexity would be $O(|V|\;log\;|V|)$ instead of the $O(|V|)$ space complexity achieved by the iterative implementation. \\

\begin{table}[H]
\caption{BFS Computational Complexities}
\label{tab:bfs}
    \begin{tabularx}{\textwidth}{|c|c|X|}
        \vtabularspace{3}
        \hline
        Resource & Complexity & \multicolumn{1}{c|}{Reasoning} \\
        \hline
        Time & $O(|V|+|E|)$ & The search must visit every node and walk every path. \\
        Space & $O(|V|)$ & The queue would have to hold $|V|-1$ nodes if the root were connected to every other node. \\
        \hline
        \vtabularspace{3}
    \end{tabularx}
\end{table}

\begin{tcolorbox}[enhanced, colback=textbook-blue, sharp corners]
    \vspace{2mm}
    \begin{center}
        \textbf{DFS and BFS are Intertwined}
    \end{center}
    
    DFS and BFS are two sides of the same coin. DFS is more natural to write recursively, and BFS is more natural to write iteratively. DFS uses a stack, and BFS uses a queue. Both searches are $O(|V|+|E|)$, so they will theoretically finish traversing the same tree in the same amount of time. However, in general, DFS will search for nodes that are far away from the source before BFS will. And, in general, BFS will search for nodes that are near the source before DFS. If you have an idea of "how distant" your desired item likely is from your source, it might be worth choosing one over the other to improve your search performance. \\
    
    The time complexity of DFS and BFS on trees can also be expressed as $O(b^d)$ where $b$ is the branching factor of the tree and $d$ is the depth of the tree. This suggests that a search is faster if the tree is narrower or shorter. To put it another way, the search is faster the closer the desired node is to the top and the left of the tree. \\
    
    DFS and BFS are used to solve a variety of fundamental computer science problems. Either one can be used to find the number of connected components in a graph. The idea is to iterate over every node in a graph and, if it has not yet been visited, to perform a DFS or BFS. The number of searches made equals the number of connected components. DFS and BFS can also be used to test if a graph is bipartite. This is done by checking if the graph can be $2$-colored. DFS is used to solve mazes. BFS is used to solve shortest path problems. \\
    
    It is interesting to think of DFS and BFS as two different kinds of personalities. DFS is like a person who is overly confident and always pressing forward, even if they are going in the wrong direction. They only take a step back if they are forced to. BFS is like a person who is overly cautious and always investigating every option before moving forward. They only move on if there is nothing else to learn around them. Both approaches are useful, but they are useful in different scenarios. \\
\end{tcolorbox}
\vspace{5mm}

\subsection{Bidirectional Search}

A bidirectional search involves performing two searches on the same graph simultaneously. They can be DFS or BFS, but they are typically BFS. This algorithm is often used to check if two nodes are connected or to solve the shortest path problem. If two breadth-first searches start at two different roots, they will search outward until one reaches a node that the other visited already. If this happens, the two roots are connected, and the shortest path goes through that intersection. The shortest path can be traced from that intersection by moving up through the intersection node's ancestry. In one search, the intersection's oldest ancestor is $s$. In the other search, it is $t$. If you wish to know not only that $s$ and $t$ are connected but also the details of their shortest path, you must keep track of the parent of every node you visit, perhaps with a map. \\

Why is this more useful approach than a regular BFS? Let $s$ and $t$ be two nodes that are $d$ edges away from each other. If you BFS starting from s, you would have to search to a depth of $d$ to find $t$, which would result in an $O(b^d)$ search time. However, if you BFS starting from both $s$ and $t$, each process would have to search to a depth of $\rfrac{d}{2}$ to find the intersection, which would result in an $O(2b^{d/2})=O(b^{d/2})$ search time, which is a major improvement. \\

\begin{algorithm}[H]
    \SetKwFunction{Bidirectional}{void bidirectional}
    \KwData{A graph $G$ and node $s$ and $t$ in $G$}
    \SetKwProg{Fn}{}{:}{}
    \Fn{\Bidirectional{$G$,$s$,$t$}}{
        \Begin{
            Let \texttt{sParentMap} and \texttt{tParentMap} be maps; \\
            Let \texttt{sQ} and \texttt{tQ} be queues; \\
            Let \texttt{sParent} and \texttt{tParent} be null nodes; \\
            Let \texttt{sCurr} and \texttt{tCurr} be null nodes; \\
            \texttt{sQ.enqueue($s$)}; \\
            \texttt{tQ.enqueue($t$)}; \\
            \While{\texttt{sQ} is not empty \textnormal{\textbf{and}} \texttt{tQ} is not empty}{
                \texttt{sCurr} $\longleftarrow$ \texttt{sQ.dequeue()}; \\
                \texttt{tCurr} $\longleftarrow$ \texttt{tQ.dequeue()}; \\
                \texttt{sParentMap.put(sCurr, sParent)}; \\
                \texttt{tParentMap.put(tCurr, tParent)}; \\
                \If{\texttt{sCurr} is visited}{
                    \texttt{printShortestPath(sCurr,sParentMap,tParentMap)};
                    \Return;
                }
                \ElseIf{\texttt{tCurr} is visited}{
                    \texttt{printShortestPath(tCurr,sParentMap,tParentMap)};
                    \Return;
                }
                Visit \texttt{sCurr}; \\
                Visit \texttt{tCurr}; \\
                \For{node \texttt{sAdj} in \texttt{G.adjacentNodes(sCurr)}}{
                    \texttt{sQ.enqueue(sAdj)};
                }
                \For{node \texttt{tAdj} in \texttt{G.adjacentNodes(tCurr)}}{
                    \texttt{tQ.enqueue(tAdj)};
                }
                \texttt{sParent} $\longleftarrow$ \texttt{sCurr}; \\
                \texttt{tParent} $\longleftarrow$ \texttt{tCurr};
            }
        }
    }
    \caption{Bidirectional Search}
\end{algorithm}
\vspace{5mm}

Consider using a bidirectional BFS to solve the search problem instead of the shortest path problem. A breadth-first search will find nearby nodes quickly. Therefore, if you had multiple guesses of where your search item might be located, it would make sense to perform breadth-first searches in all of those areas.

\subsection{Dijkstra's Algorithm}

% A* is more popular in industry

\subsection{Binary Search}

\subsection{Rabin-Karp Algorithm}

\section{Sorting}

\subsection{Selection Sort}

\subsection{Insertion Sort}

\subsection{Merge Sort}

\subsection{Quick Sort}

\subsection{Radix Sort}

\subsection{Topological Sort}

\section{Miscellaneous}

\subsection{Cache Replacement Algorithms}

\subsection{Permutations}

\subsection{Combinations}

\subsection{Bitwise Algorithms}

% What is a mask?

